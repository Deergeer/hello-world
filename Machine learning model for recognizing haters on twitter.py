# -*- coding: utf-8 -*-
"""Final Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aG_uyrQf8O8W0GyZ6aLEJ16aOZwcI57m
"""

import numpy as np
import pandas as pd
from google.colab import drive
drive.mount('/content/gdrive')

!ls '/content/gdrive/My Drive/AI_Public_Policy'

df = pd.read_csv('/content/gdrive/My Drive/AI_Public_Policy/users_neighborhood_anon.csv',encoding = "ISO-8859-1")

df.head()

df.describe()

df_clean=df[df.hate!="other"]

df_clean.head()

df_clean.describe()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt

print(df_clean.shape)

from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split

target_count = df_clean.hate.value_counts()
print('Class 0:', target_count[0])
print('Class 1:', target_count[1])
print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')

target_count.plot(kind='bar', title='Count (target)');

feature_names = ['statuses_count', 'followers_count','followees_count','favorites_count','listed_count','betweenness','sentiment','subjectivity','time_diff','time_diff_median','tweet number','retweet number','quote number','number urls','number hashtags','status length','baddies','mentions']
x=df_clean[feature_names]
y=df_clean['hate']

mask = ~np.any(np.isnan(x), axis=1)
x = x[mask]
y = y[mask]

scaler=RobustScaler()
x = scaler.fit_transform(x)

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

from sklearn.linear_model import LogisticRegression
model=LogisticRegression()
model.fit(x_train,y_train)

y_pred=model.predict(x_test)

from sklearn.metrics import accuracy_score


accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

from sklearn.metrics import confusion_matrix
from matplotlib import pyplot as plt

print(classification_report(y_test, y_pred))
plot_confusion_matrix(confusion_matrix(y_test, y_pred))

df_clean['hate'] = df_clean['hate'].astype(str)
count_class_0, count_class_1 = df_clean.hate.value_counts()

# Divide by class
df_class_majority = df_clean[df_clean['hate'] =='normal']
df_class_minority = df_clean[df_clean['hate'] =='hateful']

from sklearn.utils import resample

df_minority_upsampled = resample(df_class_minority, 
                                 replace=True,     # sample with replacement
                                 n_samples=4427,    # to match majority class
                                 random_state=123)

df_upsampled = pd.concat([df_class_majority, df_minority_upsampled])

df_upsampled.hate.value_counts()

feature_names = ['statuses_count', 'followers_count','followees_count','favorites_count','listed_count','betweenness','sentiment','subjectivity','time_diff','time_diff_median','tweet number','retweet number','quote number','number urls','number hashtags','status length']
x=df_upsampled[feature_names]
y=df_upsampled['hate']

mask = ~np.any(np.isnan(x), axis=1)
x = x[mask]
y = y[mask]

scaler=RobustScaler()
x = scaler.fit_transform(x)

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)

import time
start = time.time()

model=LogisticRegression()
model.fit(x_train,y_train)
y_pred=model.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

end=time.time()
print("traning time is:")
print(end - start)

print(classification_report(y_test, y_pred))
plot_confusion_matrix(confusion_matrix(y_test, y_pred))

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
start = time.time()

lda = LinearDiscriminantAnalysis()
lda.fit(x_train, y_train)
y_pred=lda.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

end=time.time()
print("traning time is:")
print(end - start)

print(classification_report(y_test, y_pred))
plot_confusion_matrix(confusion_matrix(y_test, y_pred))

from sklearn.neighbors import KNeighborsClassifier
start = time.time()

knn = KNeighborsClassifier()
knn.fit(x_train, y_train)
y_pred=knn.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

end=time.time()
print("traning time is:")
print(end - start)

print(classification_report(y_test, y_pred))
plot_confusion_matrix(confusion_matrix(y_test, y_pred))

from sklearn.tree import DecisionTreeClassifier
start = time.time()

clf = DecisionTreeClassifier().fit(x_train, y_train)
y_pred=clf.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

end=time.time()
print("traning time is:")
print(end - start)

print(classification_report(y_test, y_pred))
plot_confusion_matrix(confusion_matrix(y_test, y_pred))

from sklearn.naive_bayes import GaussianNB
start = time.time()

gnb = GaussianNB()
gnb.fit(x_train, y_train)
y_pred=gnb.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

end=time.time()
print("traning time is:")
print(end - start)

print(classification_report(y_test, y_pred))
plot_confusion_matrix(confusion_matrix(y_test, y_pred))

from sklearn.svm import SVC
start = time.time()

svm = SVC()
svm.fit(x_train, y_train)
y_pred=svm.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))

end=time.time()
print("traning time is:")
print(end - start)

print(classification_report(y_test, y_pred))
plot_confusion_matrix(confusion_matrix(y_test, y_pred))



